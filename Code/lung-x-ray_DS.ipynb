{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50 ,DenseNet121, EfficientNetB7,VGG16\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from keras.callbacks import ModelCheckpoint , ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# df = pd.read_csv('sufffle_image.csv')\n",
    "df = pd.read_csv('Lungs X Ray.csv')\n",
    "df[\"category\"] = df[\"category\"].replace({0: 'Normal', 1: 'COVID-19', 2: 'Viral Pneumonia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "COVID-19    140\n",
       "Normal       28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = df['category'].value_counts()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "COVID-19    140\n",
      "Normal      140\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Oversample the 'Normal' class to match the count of the majority class ('COVID-19')\n",
    "oversample = RandomOverSampler(sampling_strategy={'Normal': class_counts['COVID-19']})\n",
    "X_resampled, y_resampled = oversample.fit_resample(df.drop(columns=['category']), df['category'])\n",
    "\n",
    "# Combine the resampled data into a DataFrame\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=df.columns.drop('category'))\n",
    "df_resampled['category'] = y_resampled\n",
    "\n",
    "# Check the class distribution after oversampling\n",
    "print(df_resampled['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='category'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resampled['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = df_resampled.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(df_resampled, test_size=0.20, random_state=42)\n",
    "validate_df,test_df = train_test_split(val_df, test_size=0.50, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your IMAGE_SIZE and other parameters\n",
    "IMAGE_SIZE = (180,180)\n",
    "batch_size = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 validated image filenames belonging to 2 classes.\n",
      "Found 28 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rotation_range=15,\n",
    "#     rescale=1./255,\n",
    "#     shear_range=0.1,\n",
    "#     # zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "    \n",
    "#     brightness_range=[0.5, 1.5],\n",
    "#     channel_shift_range=0.2,\n",
    "#     vertical_flip=True,\n",
    "#     preprocessing_function=lambda x: x + 0.01 * np.random.randn(*x.shape),\n",
    "#     # random_rotation=30,\n",
    "#     height_shift_range=0.1,\n",
    "#     width_shift_range=0.1,\n",
    "#     zoom_range=[0.8, 1.2],\n",
    "#     # Exclude unsupported parameter\n",
    "# )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory=None,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df,\n",
    "    directory=None,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "      batch_size=batch_size\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze layers of the base model\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential1(model,units):\n",
    "   \n",
    "    model.add(Conv2D(units,(3,3),padding='same',activation='relu'))\n",
    "    model.add(Conv2D(units,(3,3),padding = 'same',activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides= 2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential2(model,size):\n",
    "    \n",
    "    model.add(Dense(size,activation='relu'))\n",
    "    model.add(Dense(size,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 180, 180, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 90, 90, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 90, 90, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 45, 45, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 45, 45, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 22, 22, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 11, 11, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 11, 11, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3277312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               33280     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,852,370\n",
      "Trainable params: 4,850,002\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Conv2d_2 (conv2d) (180, 180, 16) 448\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(180, 180, 3), padding='same', activation='relu'))\n",
    "# Conv2d_3 (conv2d) (180, 180, 16) 2320\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
    "# Max_pooling2d_1 (90, 90, 16) 0\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides= 2))\n",
    "sequential1(model,32)\n",
    "sequential1(model,64)\n",
    "sequential1(model,128)\n",
    "# Dropout (dropout) (11, 11, 128) 0\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "sequential1(model,256)\n",
    "\n",
    "# Dropout_1 (dropout) (5, 5, 256) 0\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten (flatten) (6400) 0\n",
    "model.add(Flatten())\n",
    "\n",
    "# Sequential_4 (sequential) (512) 3279360\n",
    "sequential2(model,512)\n",
    "sequential2(model,128)\n",
    "sequential2(model,64)\n",
    "\n",
    "\n",
    "# Dense_7 (dense) (512) 33280\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Dense_8 (dense) (3) 1539\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"custom_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_loss = CustomLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 180, 180, 16)      2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 90, 90, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 90, 90, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 45, 45, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 45, 45, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 22, 22, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 22, 22, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 22, 22, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 11, 11, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 11, 11, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 5, 5, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3277312   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               33280     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,852,370\n",
      "Trainable params: 4,850,002\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Iftek\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=Adam(lr=0.001), loss=custom_loss, metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'accuracy', \n",
    "                                            patience = 2, \n",
    "                                            verbose = 1, \n",
    "                                            factor = 0.5, \n",
    "                                            min_lr = 0.000001)\n",
    "earlystop = EarlyStopping(\n",
    "    monitor='val_loss',  # You can change this to another metric like 'val_accuracy'\n",
    "    patience=10,  # Wait for 10 epochs to see if overfitting is resolved\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "callbacks = [earlystop, learning_rate_reduction]\n",
    "# callbacks = [earlystop, learning_rate_reduction]\n",
    "# callbacks = [learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 13s 152ms/step - loss: 0.7328 - accuracy: 0.5134 - val_loss: 0.7020 - val_accuracy: 0.2143 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.7166 - accuracy: 0.5848 - val_loss: 0.8316 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.6445 - accuracy: 0.6830 - val_loss: 0.8926 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.5978 - accuracy: 0.7143 - val_loss: 1.2340 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 0.5362 - accuracy: 0.7634 - val_loss: 1.6741 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 4s 134ms/step - loss: 0.4271 - accuracy: 0.8125 - val_loss: 1.6497 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.4123 - accuracy: 0.8036 - val_loss: 6.1063 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.8080\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.4683 - accuracy: 0.8080 - val_loss: 7.6211 - val_accuracy: 0.3214 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 0.4305 - accuracy: 0.7946 - val_loss: 8.6288 - val_accuracy: 0.3214 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.8125\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 5s 143ms/step - loss: 0.4114 - accuracy: 0.8125 - val_loss: 5.8599 - val_accuracy: 0.3214 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8839Restoring model weights from the end of the best epoch: 1.\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.3628 - accuracy: 0.8839 - val_loss: 4.8707 - val_accuracy: 0.3214 - lr: 2.5000e-04\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "epochs = 100\n",
    "\n",
    "# history = model.fit_generator(\n",
    "#     train_generator,\n",
    "#     epochs=epochs,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=total_validate // batch_size,\n",
    "#     steps_per_epoch=total_train // batch_size,\n",
    "#     callbacks=callbacks\n",
    "# )\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate // batch_size,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lung_ds.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_epochs = len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "numEpochs = range(1,  actual_epochs + 1)\n",
    "plt.plot(numEpochs,history.history['accuracy'])\n",
    "plt.plot(numEpochs,history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "numEpochs = range(1,  actual_epochs + 1)\n",
    "plt.plot( numEpochs,loss, 'g', label='Training Loss')\n",
    "plt.plot(numEpochs,val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(    \n",
    "    test_df, \n",
    "    directory=None,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size = IMAGE_SIZE,\n",
    "    \n",
    "    class_mode='categorical',\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(test_generator, steps = np.ceil(nb_samples/batch_size))\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict_category'] = np.argmax(predict, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['predict_category'] = test_df['predict_category'].replace(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict_category'] = test_df['predict_category'].replace({'Normal': 0, 'COVID-19': 1, 'Viral Pneumonia': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = test_df\n",
    "correctPredictions = 0\n",
    "\n",
    "correctNormalPred = 0\n",
    "correctCovidPred = 0\n",
    "correctPneuPred = 0\n",
    "\n",
    "totalNormalPred = 0\n",
    "totalCovidPred = 0\n",
    "totalPneuPred = 0\n",
    "\n",
    "for index, row in sample_test.iterrows():\n",
    "    \n",
    "    filename = row['filename']\n",
    "    prediction = row['predict_category']\n",
    "    \n",
    "    # img = load_img(filename, target_size=IMAGE_SIZE)\n",
    "    path_parts = filename.split('\\\\')\n",
    "    third_phrase = path_parts[2]\n",
    "    # print(third_phrase)\n",
    "\n",
    "    if 'Normal' in third_phrase:\n",
    "        \n",
    "        if prediction == 0:\n",
    "            correctPredictions += 1\n",
    "            correctNormalPred += 1\n",
    "            \n",
    "        totalNormalPred += 1\n",
    "    \n",
    "    if 'COVID' in third_phrase:\n",
    "        \n",
    "        if prediction == 1: \n",
    "            correctPredictions += 1\n",
    "            correctCovidPred += 1\n",
    "            \n",
    "        totalCovidPred += 1\n",
    "    \n",
    "    if 'Viral Pneumonia' in third_phrase:\n",
    "        \n",
    "        if prediction == 2: \n",
    "            correctPredictions += 1\n",
    "            correctPneuPred += 1\n",
    "            \n",
    "        totalPneuPred += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Accuracy:', \"{:.2%}\".format(correctPredictions / test_df.shape[0]))\n",
    "print('Correct Predictions:', correctPredictions, 'Total Predictions:', test_df.shape[0])\n",
    "\n",
    "print('\\nNormal Predictions:', correctNormalPred, 'Accuracy', \"{:.2%}\".format(correctNormalPred /  totalNormalPred))\n",
    "print('COVID-19 Predictions:', correctCovidPred, 'Accuracy', \"{:.2%}\".format(correctCovidPred /  totalCovidPred))\n",
    "# print('Viral Pneumonia Predictions:', correctPneuPred, 'Accuracy', \"{:.2%}\".format(correctPneuPred / totalPneuPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for row in test_df.iterrows():\n",
    "    \n",
    "    filename = row[1][0]\n",
    "    # print(filename)\n",
    "    path_parts = filename.split('\\\\')\n",
    "    third_phrase = path_parts[2]\n",
    "    if 'Normal' in third_phrase: actual.append(0)\n",
    "    if 'COVID' in third_phrase: actual.append(1)\n",
    "    if 'Viral Pneumonia' in third_phrase: actual.append(2)\n",
    "    # print(f'Actual :{row[1][1]}')   \n",
    "    # print(f'prediction :{row[1][2]}')   \n",
    "    pred.append(row[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(actual, pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Model to Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model.load_weights('cnn3281135.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vis.visualization import visualize_saliency\n",
    "# from vis.utils import utils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scipy.ndimage as ndimage\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from keras import activations\n",
    "# from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy==1.1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
